{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessia/mambaforge/envs/deepcharuco/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from inference import infer_image, load_models\n",
    "import numpy as np\n",
    "# Load models\n",
    "deepc_path = './reference/longrun-epoch=99-step=369700.ckpt'\n",
    "refinenet_path = '/home/alessia/deepcharuco/src_100epochs/tb_logs/ckpts_refinenet/epoch=99-step=34400.ckpt'\n",
    "n_ids = 9\n",
    " # The number of corners (models pretrained use 16 for default board)\n",
    "device = 'cuda'   # use device: cpu / mps / cuda\n",
    "refinenet = load_models(refinenet_path, device='cpu')\n",
    "\n",
    "# Run inference on BGR image\n",
    "img = cv2.imread('/home/alessia/Desktop/training_dataset/render_00111.png', cv2.IMREAD_GRAYSCALE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2176, 4112)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv2.namedWindow(\"image\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"image\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "print(img.shape)\n",
    "# cv2.imshow('image',img)\n",
    "# cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "parameters = cv2.aruco.DetectorParameters_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[1001.,  181.],\n",
      "        [ 999.,  282.],\n",
      "        [ 896.,  258.],\n",
      "        [ 895.,  153.]]], dtype=float32),)\n",
      "[[1000.5511   179.51129]\n",
      " [ 999.8262   282.53683]\n",
      " [ 895.97797  260.9258 ]\n",
      " [ 893.87384  153.51767]]\n"
     ]
    }
   ],
   "source": [
    "#gray = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "detected_corners, ids, rejected = cv2.aruco.detectMarkers(img, dictionary, parameters=parameters)\n",
    "print(detected_corners)\n",
    "TERMINATION_CRITERIA = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "corners_refined = cv2.cornerSubPix(img, detected_corners[0][0], (11, 11), (-1, -1), TERMINATION_CRITERIA)\n",
    "print(corners_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "# corners_refined=np.array([[1486.3987 ,  449.76825],\n",
    "#             [1493.8314  , 532.8715 ],\n",
    "#             [1405.0139  , 540.29785],\n",
    "#             [1397.0697 ,  449.87808]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.98926086e+02 1.75761292e+02 0.00000000e+00]\n",
      " [1.00282617e+03 2.83661835e+02 1.00000000e+00]\n",
      " [8.93102966e+02 2.60800812e+02 2.00000000e+00]\n",
      " [8.96998840e+02 1.52142670e+02 3.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessia/deepcharuco/src_100epochs/./models/model_utils.py:42: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  row_indices = indices // x.shape[2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keypoints, out_img = infer_image(img, corners_refined,4, refinenet, draw_pred=True, device='cpu')\n",
    "\n",
    "print(keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('out img', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('out img', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('out img',out_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # The out_img will have corners plotted on it if draw_pred is True\n",
    "# # The keypoints format is (x, y, id_corner)\n",
    "# keypoints, out_img = infer_image(img, n_ids, deepc, refinenet, draw_pred=True, device=device)\n",
    "from inference import solve_pnp\n",
    "\n",
    "# load your intrinsics as camera_matrix and dist_coeffs\n",
    "# check calib_intrinsics for a reference how I generated them.\n",
    "# Check the solve pnp function and adapt it to your needs.\n",
    "# ret, rvec, tvec = solve_pnp(keypoints, col_count, row_count, square_len,\n",
    "#                             camera_matrix, dist_coeffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepcharuco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
