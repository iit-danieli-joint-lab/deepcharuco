{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# from inference import infer_image, load_models\n",
    "\n",
    "# # Load models\n",
    "# deepc_path = './reference/longrun-epoch=99-step=369700.ckpt'\n",
    "# refinenet_path = './reference/second-refinenet-epoch-100-step=373k.ckpt'\n",
    "# n_ids = 9\n",
    "#  # The number of corners (models pretrained use 16 for default board)\n",
    "# device = 'cuda'   # use device: cpu / mps / cuda\n",
    "# refinenet = load_models(refinenet_path, device='cuda')\n",
    "\n",
    "# Run inference on BGR image\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "#detector = cv2.aruco.ArucoDetector(dictionary, parameters)\n",
    "img = cv2.imread('/home/alessia/Desktop/test_prep/render_00001.png',cv2.IMREAD_GRAYSCALE)\n",
    "detected_corners, ids, rejected = cv2.aruco.detectMarkers(img, dictionary, parameters=parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[1332.,  591.],\n",
      "        [1226.,  574.],\n",
      "        [1250.,  477.],\n",
      "        [1355.,  495.]]], dtype=float32),)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "true=np.array([[\n",
    "                1351.4615151519317,\n",
    "                491.37359077983984\n",
    "            ],\n",
    "            [\n",
    "                1249.593499297048,\n",
    "                474.523892470125\n",
    "            ],\n",
    "            [\n",
    "                1226.601292924053,\n",
    "                568.4999200648358\n",
    "            ],\n",
    "            [\n",
    "                1329.536311643521,\n",
    "                585.3341630044895\n",
    "            ]])\n",
    "print(detected_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'COLOR_GRAY2RBG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     center_coordinates \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(detected_corners[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][j][\u001b[38;5;241m0\u001b[39m])),\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(detected_corners[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][j][\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcircle(img, center_coordinates, \u001b[38;5;241m3\u001b[39m, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_GRAY2RBG\u001b[49m)\n\u001b[1;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mnamedWindow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue corners \u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mWND_PROP_FULLSCREEN)\n\u001b[1;32m      8\u001b[0m cv2\u001b[38;5;241m.\u001b[39msetWindowProperty(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue corners \u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mWND_PROP_FULLSCREEN, cv2\u001b[38;5;241m.\u001b[39mWINDOW_FULLSCREEN)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'COLOR_GRAY2RBG'"
     ]
    }
   ],
   "source": [
    "for j in range(4):\n",
    "    center_coordinates = (int(np.round(true[j][0])),int(np.round(true[j][1])))\n",
    "    img = cv2.circle(img, center_coordinates, 1, (0,255,0), 1) \n",
    "    center_coordinates = (int(np.round(detected_corners[0][0][j][0])),int(np.round(detected_corners[0][0][j][1])))\n",
    "    img = cv2.circle(img, center_coordinates, 3, (0,0,255), 1) \n",
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.namedWindow('True corners ', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('True corners ', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('True corners ', img )\n",
    "cv2.waitKey(0) #uncomment to see the image\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, param):\n",
    "    # Check for left mouse button click\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Print the coordinates to the console\n",
    "        print(f\"Clicked coordinates: ({x}, {y})\")\n",
    "\n",
    "        # Optionally, display the coordinates on the image\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"image\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"image\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# # Display the image in a window\n",
    "# cv2.imshow('image', img)\n",
    "\n",
    "# # Set the mouse callback function to 'click_event'\n",
    "# cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "# # Wait until a key is pressed\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Destroy all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('img', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('img', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3368  615]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "keypoint=np.array([[3368., 615.]]).astype(np.int64)\n",
    "print(keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.float32\n",
      "float32\n",
      "[[3.3715000e+03 6.1187500e+02 9.2141264e+33]]\n"
     ]
    }
   ],
   "source": [
    "keypoints, out_img = infer_image(img, keypoint, 1, refinenet, draw_pred=True, device='cuda')\n",
    "\n",
    "print(keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('out img', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('out img', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('out img',out_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "cropped_image=out_img[612-12:612+12, 3368-12:3368+12]\n",
    "print(cropped_image.shape)\n",
    "cv2.namedWindow('out img', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('out img', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('out img',cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # The out_img will have corners plotted on it if draw_pred is True\n",
    "# # The keypoints format is (x, y, id_corner)\n",
    "# keypoints, out_img = infer_image(img, n_ids, deepc, refinenet, draw_pred=True, device=device)\n",
    "from inference import solve_pnp\n",
    "\n",
    "# load your intrinsics as camera_matrix and dist_coeffs\n",
    "# check calib_intrinsics for a reference how I generated them.\n",
    "# Check the solve pnp function and adapt it to your needs.\n",
    "# ret, rvec, tvec = solve_pnp(keypoints, col_count, row_count, square_len,\n",
    "#                             camera_matrix, dist_coeffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepcharuco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
